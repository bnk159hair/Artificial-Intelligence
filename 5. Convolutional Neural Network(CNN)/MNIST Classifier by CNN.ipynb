{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f71175b",
   "metadata": {},
   "source": [
    "# CNN을 이용한 MNIST 분류기\n",
    "#### tf.train.CheckpointManger API 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df0d1af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dcefa47",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251e50b1",
   "metadata": {},
   "source": [
    "MNIST 데이터를 다운로드한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b324eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train.astype('float32'), x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b19afa",
   "metadata": {},
   "source": [
    "이미지들을 float32 데이터 타입으로 변경한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b83abbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train.reshape([-1, 784]), x_test.reshape([-1, 784])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453e7f56",
   "metadata": {},
   "source": [
    "28 x 28 형태의 이미지를 784차원으로 flattening한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46d87b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x_train/255., x_test/255."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690d9bd5",
   "metadata": {},
   "source": [
    "[0, 255] 사이의 값을 [0, 1] 사이의 값으로 Normalize한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1e34fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, y_test = tf.one_hot(y_train, depth=10), tf.one_hot(y_test, depth=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac61ed9",
   "metadata": {},
   "source": [
    "레이블 데이터에 one-hot encoding을 적용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d38a758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.repeat().shuffle(60000).batch(50)\n",
    "train_data_iter = iter(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e9cf42",
   "metadata": {},
   "source": [
    "tf.data API를 이용해서 데이터를 섞고 batch 형태로 가져온다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d56209",
   "metadata": {},
   "source": [
    "### CNN 모델을 정의한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b61c1611",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(object):\n",
    "    # CNN 모델을 위한 tf.Variable들을 정의한다.\n",
    "    def __init__(self):\n",
    "        # 첫번째 Convolution Layer\n",
    "        # 5x5 Kernel Size를 가진 32개의 Filter를 적용한다.\n",
    "        self.W_conv1 = tf.Variable(tf.random.truncated_normal(shape=[5, 5, 1, 32], stddev=5e-2))\n",
    "        self.b_conv1 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "        \n",
    "        # 두번째 Convolution Layer\n",
    "        # 5x5 Kernel Size를 가진 64개의 Filter를 적용한다.\n",
    "        self.W_conv2 = tf.Variable(tf.random.truncated_normal(shape=[5, 5, 32, 64], stddev=5e-2))\n",
    "        self.b_conv2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "        \n",
    "        # Fully Connected Layer\n",
    "        # 7x7 크기를 가진 64개의 activation map을 1024개의 특징들로 변환한다.\n",
    "        self.W_fc1 = tf.Variable(tf.random.truncated_normal(shape=[7*7*64, 1024], stddev=5e-2))\n",
    "        self.b_fc1 = tf.Variable(tf.constant(0.1, shape=[1024]))\n",
    "        \n",
    "        # Outpur Layer \n",
    "        # 1024개의 특징들(feature)을 10개의 클래스-one-hot encoding으로 표현된 숫자 0~9로 변환한다.\n",
    "        self.W_output = tf.Variable(tf.random.truncated_normal(shape=[1024,10], stddev=5e-2))\n",
    "        self.b_output = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        # MNIST 데이터를 3차원 형태로 reshape한다. MNIST 데이터는 grayscale 이미지기 때문에 3번째 차원\n",
    "        # (컬러채널)의 값은 1이다.\n",
    "        x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "        \n",
    "        # 28x28x1 -> 28x28x32\n",
    "        h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, self.W_conv1, strides=[1, 1, 1, 1], padding='SAME') + self.b_conv1)\n",
    "        \n",
    "        # 28x28x32 -> 14x14x32\n",
    "        h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "        # 14x14x32 -> 14x14x64\n",
    "        h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, self.W_conv2, strides=[1, 1, 1, 1], padding='SAME') + self.b_conv2)\n",
    "        \n",
    "        # 14x14x64 -> 7x7x64\n",
    "        h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "        \n",
    "        # 7x7x64(3136) -> 1024\n",
    "        h_pool2_flat = tf.reshape(h_pool2, [-1, 7 * 7 *64])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, self.W_fc1) + self.b_fc1)\n",
    "        \n",
    "        # 1024 -> 10\n",
    "        logits = tf.matmul(h_fc1, self.W_output) + self.b_output\n",
    "        y_pred = tf.nn.softmax(logits)\n",
    "        \n",
    "        return y_pred, logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be45fd5f",
   "metadata": {},
   "source": [
    "### cross-entropy 손실 함수를 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ee92913",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def cross_entropy_loss(logits, y):\n",
    "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4ec76b",
   "metadata": {},
   "source": [
    "### 최적화를 위한 Adam 옵티마이저를 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d630f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e279655",
   "metadata": {},
   "source": [
    "### 최적화를 위한 function을 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8819f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred, logits = model(x)\n",
    "        loss = cross_entropy_loss(logits, y)\n",
    "    gradients = tape.gradient(loss, vars(model).values())\n",
    "    optimizer.apply_gradients(zip(gradients, vars(model).values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a81709f",
   "metadata": {},
   "source": [
    "### 모델의 정확도를 출력하는 함수를 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42300b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def compute_accuracy(y_pred, y):\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf696bbc",
   "metadata": {},
   "source": [
    "### Convolutional Neural Networks (CNN) 모델을 선언한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "454f9552",
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb6a12d",
   "metadata": {},
   "source": [
    "tf.train.CheckpointManager를 이용해서 파라미터를 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cae37e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVER_DIR = \"./model\"\n",
    "ckpt = tf.train.Checkpoint(**vars(CNN_model))\n",
    "ckpt_manager = tf.train.CheckpointManager(ckpt, directory=SAVER_DIR, max_to_keep=5)\n",
    "latest_ckpt = tf.train.latest_checkpoint(SAVER_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58dbc5a4",
   "metadata": {},
   "source": [
    "만약 저장된 모델과 파라미터가 있으면 이를 불러오고 (Restore)\n",
    "Restored 모델을 이용해서 테스트 데이터에 대한 정확도를 출력하고 프로그램을 종료한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64373270",
   "metadata": {},
   "outputs": [],
   "source": [
    "if latest_ckpt:\n",
    "    ckpt.restore(latest_ckpt)\n",
    "    print(\"테스트 데이터 정확도 (Restored) : %f\" %compute_accuracy(CNN_model(x_test)[0], y_test))\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa5279a",
   "metadata": {},
   "source": [
    "10000 step만큼 최적화를 수행한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6b3ceaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 0, 트레이닝 데이터 정확도: 0.080000\n",
      "반복(Epoch): 100, 트레이닝 데이터 정확도: 0.900000\n",
      "반복(Epoch): 200, 트레이닝 데이터 정확도: 0.900000\n",
      "반복(Epoch): 300, 트레이닝 데이터 정확도: 0.960000\n",
      "반복(Epoch): 400, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 500, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 600, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 700, 트레이닝 데이터 정확도: 0.920000\n",
      "반복(Epoch): 800, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 900, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 1000, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 1100, 트레이닝 데이터 정확도: 0.960000\n",
      "반복(Epoch): 1200, 트레이닝 데이터 정확도: 0.940000\n",
      "반복(Epoch): 1300, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 1400, 트레이닝 데이터 정확도: 0.940000\n",
      "반복(Epoch): 1500, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 1600, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 1700, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 1800, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 1900, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 2000, 트레이닝 데이터 정확도: 0.960000\n",
      "반복(Epoch): 2100, 트레이닝 데이터 정확도: 0.960000\n",
      "반복(Epoch): 2200, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 2300, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 2400, 트레이닝 데이터 정확도: 0.960000\n",
      "반복(Epoch): 2500, 트레이닝 데이터 정확도: 0.960000\n",
      "반복(Epoch): 2600, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 2700, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 2800, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 2900, 트레이닝 데이터 정확도: 0.940000\n",
      "반복(Epoch): 3000, 트레이닝 데이터 정확도: 0.960000\n",
      "반복(Epoch): 3100, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 3200, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 3300, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 3400, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 3500, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 3600, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 3700, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 3800, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 3900, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 4000, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 4100, 트레이닝 데이터 정확도: 0.960000\n",
      "반복(Epoch): 4200, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 4300, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 4400, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 4500, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 4600, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 4700, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 4800, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 4900, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 5000, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 5100, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 5200, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 5300, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 5400, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 5500, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 5600, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 5700, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 5800, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 5900, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 6000, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 6100, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 6200, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 6300, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 6400, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 6500, 트레이닝 데이터 정확도: 0.960000\n",
      "반복(Epoch): 6600, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 6700, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 6800, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 6900, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 7000, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 7100, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 7200, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 7300, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 7400, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 7500, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 7600, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 7700, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 7800, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 7900, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 8000, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 8100, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 8200, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 8300, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 8400, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 8500, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 8600, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 8700, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 8800, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 8900, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 9000, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 9100, 트레이닝 데이터 정확도: 0.980000\n",
      "반복(Epoch): 9200, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 9300, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 9400, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 9500, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 9600, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 9700, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 9800, 트레이닝 데이터 정확도: 1.000000\n",
      "반복(Epoch): 9900, 트레이닝 데이터 정확도: 0.980000\n"
     ]
    }
   ],
   "source": [
    "for step in range(10000):\n",
    "    # 50개씩 MNIST 데이터를 불러온다.\n",
    "    batch_x, batch_y = next(train_data_iter)\n",
    "    # 100 Step마다 training 데이터셋에 대한 정확도를 출력하고 tf.train.CheckpointManager를 이용해서 파라미터를 저장한다.\n",
    "    if step % 100 ==0:\n",
    "        ckpt_manager.save(checkpoint_number=step)\n",
    "        train_accuracy = compute_accuracy(CNN_model(batch_x)[0], batch_y)\n",
    "        print(\"반복(Epoch): %d, 트레이닝 데이터 정확도: %f\" % (step, train_accuracy))\n",
    "    # 옵티마이저를 실행해 파라미터를 한스텝 업데이트한다.\n",
    "    train_step(CNN_model, batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b590a2bb",
   "metadata": {},
   "source": [
    "#### 학습이 끝나면 테스트 데이터에 대한 정확도를 출력한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "367c6a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도(Accuracy): 0.990500\n"
     ]
    }
   ],
   "source": [
    "print(\"정확도(Accuracy): %f\" % compute_accuracy(CNN_model(x_test)[0], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c70a83c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
